[{"role": "system", "content": "You are a helpful AI bot that answers questions for a user. Keep your response short and direct"}, {"role": "user", "content": "\nThe best thing to do in San Francisco is eat a sandwich and sit in Dolores Park on a sunny day.\n September 2007In high school I decided I was going to study philosophy in college.\nI had several motives, some more honorable than others.  One of the\nless honorable was to shock people.  College was regarded as job\ntraining where I grew up, so studying philosophy seemed an impressively\nimpractical thing to do.  Sort of like slashing holes in your clothes\nor putting a safety pin through your ear, which were other forms\nof impressive impracticality then just coming into fashion.But I had some more honest motives as well.  I thought studying\nphilosophy would be a shortcut straight to wisdom.  All the people\nmajoring in other things would just end up with a bunch of domain\nknowledge.  I would be learning what was really what.I'd tried to read a few philosophy books.  Not recent ones; you\nwouldn't find those in our high school library.  But I tried to\nread Plato and Aristotle.  I doubt I believed I understood them,\nbut they sounded like they were talking about something important.\nI assumed I'd learn what in college.The summer before senior year I took some college classes.  I learned\na lot in the calculus class, but I didn't learn much in Philosophy\n101.  And yet my plan to study philosophy remained intact.  It was\nmy fault I hadn't learned anything.  I hadn't read the books we\nwere assigned carefully enough.  I'd give Berkeley's Principles\nof Human Knowledge another shot in college.  Anything so admired\nand so difficult to read must have something in it, if one could\nonly figure out what.Twenty-six years later, I still don't understand Berkeley.  I have\na nice edition of his collected works.  Will I ever read it?  Seems\nunlikely.The difference between then and now is that now I understand why\nBerkeley is probably not worth trying to understand.  I think I see\nnow what went wrong with philosophy, and how we might fix it.WordsI did end up being a philosophy major for most of college.  It\ndidn't work out as I'd hoped.  I didn't learn any magical truths\ncompared to which everything else was mere domain knowledge.  But\nI do at least know now why I didn't.  Philosophy doesn't really\nhave a subject matter in the way math or history or most other\nuniversity subjects do.  There is no core of knowledge one must\nmaster.  The closest you come to that is a knowledge of what various\nindividual philosophers have said about different topics over the\nyears.  Few were sufficiently correct that people have forgotten\nwho discovered what they discovered.Formal logic has some subject matter. I took several classes in\nlogic.  I don't know if I learned anything from them.\n[1]\nIt does seem to me very important to be able to flip ideas around in\none's head: to see when two ideas don't fully cover the space of\npossibilities, or when one idea is the same as another but with a\ncouple things changed.  But did studying logic teach me the importance\nof thinking this way, or make me any better at it?  I don't know.There are things I know I learned from studying philosophy.  The\nmost dramatic I learned immediately, in the first semester of\nfreshman year, in a class taught by Sydney Shoemaker.  I learned\nthat I don't exist.  I am (and you are) a collection of cells that\nlurches around driven by various forces, and calls itself I.  But\nthere's no central, indivisible thing that your identity goes with.\nYou could conceivably lose half your brain and live.  Which means\nyour brain could conceivably be split into two halves and each\ntransplanted into different bodies.  Imagine waking up after such\nan operation.  You have to imagine being two people.The real lesson here is that the concepts we use in everyday life\nare fuzzy, and break down if pushed too hard.  Even a concept as\ndear to us as I.  It took me a while to grasp this, but when I\ndid it was fairly sudden, like someone in the nineteenth century\ngrasping evolution and realizing the story of creation they'd been\ntold as a child was all wrong. \n[2]\nOutside of math there's a limit\nto how far you can push words; in fact, it would not be a bad\ndefinition of math to call it the study of terms that have precise\nmeanings.  Everyday words are inherently imprecise.  They work well\nenough in everyday life that you don't notice.  Words seem to work,\njust as Newtonian physics seems to.  But you can always make them\nbreak if you push them far enough.I would say that this has been, unfortunately for philosophy, the\ncentral fact of philosophy.  Most philosophical debates are not\nmerely afflicted by but driven by confusions over words.  Do we\nhave free will?  Depends what you mean by \"free.\" Do abstract ideas\nexist?  Depends what you mean by \"exist.\"Wittgenstein is popularly credited with the idea that most philosophical\ncontroversies are due to confusions over language.  I'm not sure\nhow much credit to give him.  I suspect a lot of people realized\nthis, but reacted simply by not studying philosophy, rather than\nbecoming philosophy professors.How did things get this way?  Can something people have spent\nthousands of years studying really be a waste of time?  Those are\ninteresting questions.  In fact, some of the most interesting\nquestions you can ask about philosophy.  The most valuable way to\napproach the current philosophical tradition may be neither to get\nlost in pointless speculations like Berkeley, nor to shut them down\nlike Wittgenstein, but to study it as an example of reason gone\nwrong.HistoryWestern philosophy really begins with Socrates, Plato, and Aristotle.\nWhat we know of their predecessors comes from fragments and references\nin later works; their doctrines could be described as speculative\ncosmology that occasionally strays into analysis.  Presumably they\nwere driven by whatever makes people in every other society invent\ncosmologies.\n[3]With Socrates, Plato, and particularly Aristotle, this tradition\nturned a corner.  There started to be a lot more analysis.  I suspect\nPlato and Aristotle were encouraged in this by progress in math.\nMathematicians had by then shown that you could figure things out\nin a much more conclusive way than by making up fine sounding stories\nabout them.  \n[4]People talk so much about abstractions now that we don't realize\nwhat a leap it must have been when they first started to.  It was\npresumably many thousands of years between when people first started\ndescribing things as hot or cold and when someone asked \"what is\nheat?\"  No doubt it was a very gradual process.  We don't know if\nPlato or Aristotle were the first to ask any of the questions they\ndid.  But their works are the oldest we have that do this on a large\nscale, and there is a freshness (not to say naivete) about them\nthat suggests some of the questions they asked were new to them,\nat least.Aristotle in particular reminds me of the phenomenon that happens\nwhen people discover something new, and are so excited by it that\nthey race through a huge percentage of the newly discovered territory\nin one lifetime.  If so, that's evidence of how new this kind of\nthinking was. \n[5]This is all to explain how Plato and Aristotle can be very impressive\nand yet naive and mistaken.  It was impressive even to ask the\nquestions they did.  That doesn't mean they always came up with\ngood answers.  It's not considered insulting to say that ancient\nGreek mathematicians were naive in some respects, or at least lacked\nsome concepts that would have made their lives easier.  So I hope\npeople will not be too offended if I propose that ancient philosophers\nwere similarly naive.  In particular, they don't seem to have fully\ngrasped what I earlier called the central fact of philosophy: that\nwords break if you push them too far.\"Much to the surprise of the builders of the first digital computers,\"\nRod Brooks wrote, \"programs written for them usually did not work.\"\n[6]\nSomething similar happened when people first started trying\nto talk about abstractions.  Much to their surprise, they didn't\narrive at answers they agreed upon.  In fact, they rarely seemed\nto arrive at answers at all.They were in effect arguing about artifacts induced by sampling at\ntoo low a resolution.The proof of how useless some of their answers turned out to be is\nhow little effect they have.  No one after reading Aristotle's\nMetaphysics does anything differently as a result.\n[7]Surely I'm not claiming that ideas have to have practical applications\nto be interesting?  No, they may not have to.  Hardy's boast that\nnumber theory had no use whatsoever wouldn't disqualify it.  But\nhe turned out to be mistaken.  In fact, it's suspiciously hard to\nfind a field of math that truly has no practical use.  And Aristotle's\nexplanation of the ultimate goal of philosophy in Book A of the\nMetaphysics implies that philosophy should be useful too.Theoretical KnowledgeAristotle's goal was to find the most general of general principles.\nThe examples he gives are convincing: an ordinary worker builds\nthings a certain way out of habit; a master craftsman can do more\nbecause he grasps the underlying principles.  The trend is clear:\nthe more general the knowledge, the more admirable it is.  But then\nhe makes a mistake\u2014possibly the most important mistake in the\nhistory of philosophy.  He has noticed that theoretical knowledge\nis often acquired for its own sake, out of curiosity, rather than\nfor any practical need.  So he proposes there are two kinds of\ntheoretical knowledge: some that's useful in practical matters and\nsome that isn't.  Since people interested in the latter are interested\nin it for its own sake, it must be more noble.  So he sets as his\ngoal in the Metaphysics the exploration of knowledge that has no\npractical use.  Which means no alarms go off when he takes on grand\nbut vaguely understood questions and ends up getting lost in a sea\nof words.His mistake was to confuse motive and result.  Certainly, people\nwho want a deep understanding of something are often driven by\ncuriosity rather than any practical need.  But that doesn't mean\nwhat they end up learning is useless.  It's very valuable in practice\nto have a deep understanding of what you're doing; even if you're\nnever called on to solve advanced problems, you can see shortcuts\nin the solution of simple ones, and your knowledge won't break down\nin edge cases, as it would if you were relying on formulas you\ndidn't understand.  Knowledge is power.  That's what makes theoretical\nknowledge prestigious.  It's also what causes smart people to be\ncurious about certain things and not others; our DNA is not so\ndisinterested as we might think.So while ideas don't have to have immediate practical applications\nto be interesting, the kinds of things we find interesting will\nsurprisingly often turn out to have practical applications.The reason Aristotle didn't get anywhere in the Metaphysics was\npartly that he set off with contradictory aims: to explore the most\nabstract ideas, guided by the assumption that they were useless.\nHe was like an explorer looking for a territory to the north of\nhim, starting with the assumption that it was located to the south.And since his work became the map used by generations of future\nexplorers, he sent them off in the wrong direction as well. \n[8]\nPerhaps worst of all, he protected them from both the criticism of\noutsiders and the promptings of their own inner compass by establishing\nthe principle that the most noble sort of theoretical knowledge had\nto be useless.The Metaphysics is mostly a failed experiment.  A few ideas from\nit turned out to be worth keeping; the bulk of it has had no effect\nat all.  The Metaphysics is among the least read of all famous\nbooks.  It's not hard to understand the way Newton's Principia\nis, but the way a garbled message is.Arguably it's an interesting failed experiment.  But unfortunately\nthat was not the conclusion Aristotle's successors derived from\nworks like the Metaphysics. \n[9]\nSoon after, the western world\nfell on intellectual hard times.  Instead of version 1s to be\nsuperseded, the works of Plato and Aristotle became revered texts\nto be mastered and discussed.  And so things remained for a shockingly\nlong time.  It was not till around 1600 (in Europe, where the center\nof gravity had shifted by then) that one found people confident\nenough to treat Aristotle's work as a catalog of mistakes.  And\neven then they rarely said so outright.If it seems surprising that the gap was so long, consider how little\nprogress there was in math between Hellenistic times and the\nRenaissance.In the intervening years an unfortunate idea took hold:  that it\nwas not only acceptable to produce works like the Metaphysics,\nbut that it was a particularly prestigious line of work, done by a\nclass of people called philosophers.  No one thought to go back and\ndebug Aristotle's motivating argument.  And so instead of correcting\nthe problem Aristotle discovered by falling into it\u2014that you can\neasily get lost if you talk too loosely about very abstract ideas\u2014they \ncontinued to fall into it.The SingularityCuriously, however, the works they produced continued to attract\nnew readers.  Traditional philosophy occupies a kind of singularity\nin this respect.  If you write in an unclear way about big ideas,\nyou produce something that seems tantalizingly attractive to\ninexperienced but intellectually ambitious students.  Till one knows\nbetter, it's hard to distinguish something that's hard to understand\nbecause the writer was unclear in his own mind from something like\na mathematical proof that's hard to understand because the ideas\nit represents are hard to understand.  To someone who hasn't learned\nthe difference, traditional philosophy seems extremely attractive:\nas hard (and therefore impressive) as math, yet broader in scope.\nThat was what lured me in as a high school student.This singularity is even more singular in having its own defense\nbuilt in.  When things are hard to understand, people who suspect\nthey're nonsense generally keep quiet.  There's no way to prove a\ntext is meaningless.  The closest you can get is to show that the\nofficial judges of some class of texts can't distinguish them from\nplacebos. \n[10]And so instead of denouncing philosophy, most people who suspected\nit was a waste of time just studied other things.  That alone is\nfairly damning evidence, considering philosophy's claims.  It's\nsupposed to be about the ultimate truths. Surely all smart people\nwould be interested in it, if it delivered on that promise.Because philosophy's flaws turned away the sort of people who might\nhave corrected them, they tended to be self-perpetuating.  Bertrand\nRussell wrote in a letter in 1912:\n\n  Hitherto the people attracted to philosophy have been mostly those\n  who loved the big generalizations, which were all wrong, so that\n  few people with exact minds have taken up the subject.\n[11]\n\nHis response was to launch Wittgenstein at it, with dramatic results.I think Wittgenstein deserves to be famous not for the discovery\nthat most previous philosophy was a waste of time, which judging\nfrom the circumstantial evidence must have been made by every smart\nperson who studied a little philosophy and declined to pursue it\nfurther, but for how he acted in response.\n[12]\nInstead of quietly\nswitching to another field, he made a fuss, from inside.  He was\nGorbachev.The field of philosophy is still shaken from the fright Wittgenstein\ngave it. \n[13]\nLater in life he spent a lot of time talking about\nhow words worked.  Since that seems to be allowed, that's what a\nlot of philosophers do now.  Meanwhile, sensing a vacuum in the\nmetaphysical speculation department, the people who used to do\nliterary criticism have been edging Kantward, under new names like\n\"literary theory,\" \"critical theory,\" and when they're feeling\nambitious, plain \"theory.\"  The writing is the familiar word salad:\n\n  Gender is not like some of the other grammatical modes which\n  express precisely a mode of conception without any reality that\n  corresponds to the conceptual mode, and consequently do not express\n  precisely something in reality by which the intellect could be\n  moved to conceive a thing the way it does, even where that motive\n  is not something in the thing as such.\n  [14]\n\nThe singularity I've described is not going away.  There's a market\nfor writing that sounds impressive and can't be disproven. There\nwill always be both supply and demand.  So if one group abandons\nthis territory, there will always be others ready to occupy it.A ProposalWe may be able to do better.  Here's an intriguing possibility.\nPerhaps we should do what Aristotle meant to do, instead of what\nhe did.  The goal he announces in the Metaphysics seems one worth\npursuing: to discover the most general truths.  That sounds good.\nBut instead of trying to discover them because they're useless,\nlet's try to discover them because they're useful.I propose we try again, but that we use that heretofore despised\ncriterion, applicability, as a guide to keep us from wondering\noff into a swamp of abstractions.  Instead of trying to answer the\nquestion:\n\n  What are the most general truths?\n\nlet's try to answer the question\n\n  Of all the useful things we can say, which are the most general?\n\nThe test of utility I propose is whether we cause people who read\nwhat we've written to do anything differently afterward.  Knowing\nwe have to give definite (if implicit) advice will keep us from\nstraying beyond the resolution of the words we're using.The goal is the same as Aristotle's; we just approach it from a\ndifferent direction.As an example of a useful, general idea, consider that of the\ncontrolled experiment.  There's an idea that has turned out to be\nwidely applicable.  Some might say it's part of science, but it's\nnot part of any specific science; it's literally meta-physics (in\nour sense of \"meta\").   The idea of evolution is another. It turns\nout to have quite broad applications\u2014for example, in genetic\nalgorithms and even product design.  Frankfurt's distinction between\nlying and bullshitting seems a promising recent example.\n[15]These seem to me what philosophy should look like: quite general\nobservations that would cause someone who understood them to do\nsomething differently.Such observations will necessarily be about things that are imprecisely\ndefined.  Once you start using words with precise meanings, you're\ndoing math.  So starting from utility won't entirely solve the\nproblem I described above\u2014it won't flush out the metaphysical\nsingularity.  But it should help.  It gives people with good\nintentions a new roadmap into abstraction.  And they may thereby\nproduce things that make the writing of the people with bad intentions\nlook bad by comparison.One drawback of this approach is that it won't produce the sort of\nwriting that gets you tenure.  And not just because it's not currently\nthe fashion.  In order to get tenure in any field you must not\narrive at conclusions that members of tenure committees can disagree\nwith.  In practice there are two kinds of solutions to this problem.\nIn math and the sciences, you can prove what you're saying, or at\nany rate adjust your conclusions so you're not claiming anything\nfalse (\"6 of 8 subjects had lower blood pressure after the treatment\").\nIn the humanities you can either avoid drawing any definite conclusions\n(e.g. conclude that an issue is a complex one), or draw conclusions\nso narrow that no one cares enough to disagree with you.The kind of philosophy I'm advocating won't be able to take either\nof these routes.  At best you'll be able to achieve the essayist's\nstandard of proof, not the mathematician's or the experimentalist's.\nAnd yet you won't be able to meet the usefulness test without\nimplying definite and fairly broadly applicable conclusions.  Worse\nstill, the usefulness test will tend to produce results that annoy\npeople: there's no use in telling people things they already believe,\nand people are often upset to be told things they don't.Here's the exciting thing, though.  Anyone can do this.  Getting\nto general plus useful by starting with useful and cranking up the\ngenerality may be unsuitable for junior professors trying to get\ntenure, but it's better for everyone else, including professors who\nalready have it.  This side of the mountain is a nice gradual slope.\nYou can start by writing things that are useful but very specific,\nand then gradually make them more general.  Joe's has good burritos.\nWhat makes a good burrito?  What makes good food?  What makes\nanything good?  You can take as long as you want.  You don't have\nto get all the way to the top of the mountain.  You don't have to\ntell anyone you're doing philosophy.If it seems like a daunting task to do philosophy, here's an\nencouraging thought.  The field is a lot younger than it seems.\nThough the first philosophers in the western tradition lived about\n2500 years ago, it would be misleading to say the field is 2500\nyears old, because for most of that time the leading practitioners\nweren't doing much more than writing commentaries on Plato or\nAristotle while watching over their shoulders for the next invading\narmy.  In the times when they weren't, philosophy was hopelessly\nintermingled with religion.  It didn't shake itself free till a\ncouple hundred years ago, and even then was afflicted by the\nstructural problems I've described above.  If I say this, some will\nsay it's a ridiculously overbroad and uncharitable generalization,\nand others will say it's old news, but here goes: judging from their\nworks, most philosophers up to the present have been wasting their\ntime.  So in a sense the field is still at the first step. \n[16]That sounds a preposterous claim to make.  It won't seem so\npreposterous in 10,000 years.  Civilization always seems old, because\nit's always the oldest it's ever been.  The only way to say whether\nsomething is really old or not is by looking at structural evidence,\nand structurally philosophy is young; it's still reeling from the\nunexpected breakdown of words.Philosophy is as young now as math was in 1500.  There is a lot\nmore to discover.Notes\n[1]\nIn practice formal logic is not much use, because despite\nsome progress in the last 150 years we're still only able to formalize\na small percentage of statements.  We may never do that much better,\nfor the same reason 1980s-style \"knowledge representation\" could\nnever have worked; many statements may have no representation more\nconcise than a huge, analog brain state.[2]\nIt was harder for Darwin's contemporaries to grasp this than\nwe can easily imagine.  The story of creation in the Bible is not\njust a Judeo-Christian concept; it's roughly what everyone must\nhave believed since before people were people.  The hard part of\ngrasping evolution was to realize that species weren't, as they\nseem to be, unchanging, but had instead evolved from different,\nsimpler organisms over unimaginably long periods of time.Now we don't have to make that leap.  No one in an industrialized\ncountry encounters the idea of evolution for the first time as an\nadult.  Everyone's taught about it as a child, either as truth or\nheresy.[3]\nGreek philosophers before Plato wrote in verse.  This must\nhave affected what they said.  If you try to write about the nature\nof the world in verse, it inevitably turns into incantation.  Prose\nlets you be more precise, and more tentative.[4]\nPhilosophy is like math's\nne'er-do-well brother.  It was born when Plato and Aristotle looked\nat the works of their predecessors and said in effect \"why can't\nyou be more like your brother?\"  Russell was still saying the same\nthing 2300 years later.Math is the precise half of the most abstract ideas, and philosophy\nthe imprecise half.  It's probably inevitable that philosophy will\nsuffer by comparison, because there's no lower bound to its precision.\nBad math is merely boring, whereas bad philosophy is nonsense.  And\nyet there are some good ideas in the imprecise half.[5]\nAristotle's best work was in logic and zoology, both of which\nhe can  be said to have invented.  But the most dramatic departure\nfrom his predecessors was a new, much more analytical style of\nthinking.  He was arguably the first scientist.[6]\nBrooks, Rodney, Programming in Common Lisp, Wiley, 1985, p.\n94.[7]\nSome would say we depend on Aristotle more than we realize,\nbecause his ideas were one of the ingredients in our common culture.\nCertainly a lot of the words we use have a connection with Aristotle,\nbut it seems a bit much to suggest that we wouldn't have the concept\nof the essence of something or the distinction between matter and\nform if Aristotle hadn't written about them.One way to see how much we really depend on Aristotle would be to\ndiff European culture with Chinese: what ideas did European culture\nhave in 1800 that Chinese culture didn't, in virtue of Aristotle's\ncontribution?[8]\nThe meaning of the word \"philosophy\" has changed over time.\nIn ancient times it covered a broad range of topics, comparable in\nscope to our \"scholarship\" (though without the methodological\nimplications).  Even as late as Newton's time it included what we\nnow call \"science.\"  But core of the subject today is still what\nseemed to Aristotle the core: the attempt to discover the most\ngeneral truths.Aristotle didn't call this \"metaphysics.\"  That name got assigned\nto it because the books we now call the Metaphysics came after\n(meta = after) the Physics in the standard edition of Aristotle's\nworks compiled by Andronicus of Rhodes three centuries later.  What\nwe call \"metaphysics\" Aristotle called \"first philosophy.\"[9]\nSome of Aristotle's immediate successors may have realized\nthis, but it's hard to say because most of their works are lost.[10]\nSokal, Alan, \"Transgressing the Boundaries: Toward a Transformative\nHermeneutics of Quantum Gravity,\" Social Text 46/47, pp. 217-252.Abstract-sounding nonsense seems to be most attractive when it's\naligned with some axe the audience already has to grind.  If this\nis so we should find it's most popular with groups that are (or\nfeel) weak.  The powerful don't need its reassurance.[11]\nLetter to Ottoline Morrell, December 1912.  Quoted in:Monk, Ray, Ludwig Wittgenstein: The Duty of Genius, Penguin, 1991,\np. 75.[12]\nA preliminary result, that all metaphysics between Aristotle\nand 1783 had been a waste of time, is due to I. Kant.[13]\nWittgenstein asserted a sort of mastery to which the inhabitants\nof early 20th century Cambridge seem to have been peculiarly\nvulnerable\u2014perhaps partly because so many had been raised religious\nand then stopped believing, so had a vacant space in their heads\nfor someone to tell them what to do (others chose Marx or Cardinal\nNewman), and partly because a quiet, earnest place like Cambridge\nin that era had no natural immunity to messianic figures, just as\nEuropean politics then had no natural immunity to dictators.[14]\nThis is actually from the Ordinatio of Duns Scotus (ca.\n1300), with \"number\" replaced by \"gender.\"  Plus ca change.Wolter, Allan (trans), Duns Scotus: Philosophical Writings, Nelson,\n1963, p. 92.[15]\nFrankfurt, Harry, On Bullshit,  Princeton University Press,\n2005.[16]\nSome introductions to philosophy now take the line that\nphilosophy is worth studying as a process rather than for any\nparticular truths you'll learn.  The philosophers whose works they\ncover would be rolling in their graves at that.  They hoped they\nwere doing more than serving as examples of how to argue: they hoped\nthey were getting results.  Most were wrong, but it doesn't seem\nan impossible hope.This argument seems to me like someone in 1500 looking at the lack\nof results achieved by alchemy and saying its value was as a process.\nNo, they were going about it wrong.  It turns out it is possible\nto transmute lead into gold (though not economically at current\nenergy prices), but the route to that knowledge was to\nbacktrack and try another approach.Thanks to Trevor Blackwell, Paul Buchheit, Jessica Livingston, \nRobert Morris, Mark Nitzberg, and Peter Norvig for reading drafts of this.November 2022Since I was about 9 I've been puzzled by the apparent contradiction\nbetween being made of matter that behaves in a predictable way, and\nthe feeling that I could choose to do whatever I wanted. At the\ntime I had a self-interested motive for exploring the question. At\nthat age (like most succeeding ages) I was always in trouble with\nthe authorities, and it seemed to me that there might possibly be\nsome way to get out of trouble by arguing that I wasn't responsible\nfor my actions. I gradually lost hope of that, but the puzzle\nremained: How do you reconcile being a machine made of matter with\nthe feeling that you're free to choose what you do?\n[1]The best way to explain the answer may be to start with a slightly\nwrong version, and then fix it. The wrong version is: You can do\nwhat you want, but you can't want what you want. Yes, you can control\nwhat you do, but you'll do what you want, and you can't control\nthat.The reason this is mistaken is that people do sometimes change what\nthey want. People who don't want to want something \u2014 drug addicts,\nfor example \u2014 can sometimes make themselves stop wanting it. And\npeople who want to want something \u2014 who want to like classical\nmusic, or broccoli \u2014 sometimes succeed.So we modify our initial statement: You can do what you want, but\nyou can't want to want what you want.That's still not quite true. It's possible to change what you want\nto want. I can imagine someone saying \"I decided to stop wanting\nto like classical music.\" But we're getting closer to the truth.\nIt's rare for people to change what they want to want, and the more\n\"want to\"s we add, the rarer it gets.We can get arbitrarily close to a true statement by adding more \"want\nto\"s in much the same way we can get arbitrarily close to 1 by adding\nmore 9s to a string of 9s following a decimal point. In practice\nthree or four \"want to\"s must surely be enough. It's hard even to\nenvision what it would mean to change what you want to want to want\nto want, let alone actually do it.So one way to express the correct answer is to use a regular\nexpression. You can do what you want, but there's some statement\nof the form \"you can't (want to)* want what you want\" that's true.\nUltimately you get back to a want that you don't control.\n[2]\nNotes[1]\nI didn't know when I was 9 that matter might behave randomly,\nbut I don't think it affects the problem much. Randomness destroys\nthe ghost in the machine as effectively as determinism.[2]\nIf you don't like using an expression, you can make the same\npoint using higher-order desires: There is some n such that you\ndon't control your nth-order desires.\nThanks to Trevor Blackwell,\nJessica Livingston, Robert Morris, and\nMichael Nielsen for reading drafts of this.December 2014If the world were static, we could have monotonically increasing\nconfidence in our beliefs.  The more (and more varied) experience\na belief survived, the less likely it would be false.  Most people\nimplicitly believe something like this about their opinions.  And\nthey're justified in doing so with opinions about things that don't\nchange much, like human nature.  But you can't trust your opinions\nin the same way about things that change, which could include\npractically everything else.When experts are wrong, it's often because they're experts on an\nearlier version of the world.Is it possible to avoid that?  Can you protect yourself against\nobsolete beliefs?  To some extent, yes. I spent almost a decade\ninvesting in early stage startups, and curiously enough protecting\nyourself against obsolete beliefs is exactly what you have to do\nto succeed as a startup investor.  Most really good startup ideas\nlook like bad ideas at first, and many of those look bad specifically\nbecause some change in the world just switched them from bad to\ngood.  I spent a lot of time learning to recognize such ideas, and\nthe techniques I used may be applicable to ideas in general.The first step is to have an explicit belief in change.  People who\nfall victim to a monotonically increasing confidence in their\nopinions are implicitly concluding the world is static.  If you\nconsciously remind yourself it isn't, you start to look for change.Where should one look for it?  Beyond the moderately useful\ngeneralization that human nature doesn't change much, the unfortunate\nfact is that change is hard to predict.  This is largely a tautology\nbut worth remembering all the same: change that matters usually\ncomes from an unforeseen quarter.So I don't even try to predict it.  When I get asked in interviews\nto predict the future, I always have to struggle to come up with\nsomething plausible-sounding on the fly, like a student who hasn't\nprepared for an exam.\n[1]\nBut it's not out of laziness that I haven't\nprepared.  It seems to me that beliefs about the future are so\nrarely correct that they usually aren't worth the extra rigidity\nthey impose, and that the best strategy is simply to be aggressively\nopen-minded.  Instead of trying to point yourself in the right\ndirection, admit you have no idea what the right direction is, and\ntry instead to be super sensitive to the winds of change.It's ok to have working hypotheses, even though they may constrain\nyou a bit, because they also motivate you.  It's exciting to chase\nthings and exciting to try to guess answers.  But you have to be\ndisciplined about not letting your hypotheses harden into anything\nmore.\n[2]I believe this passive m.o. works not just for evaluating new ideas\nbut also for having them.  The way to come up with new ideas is not\nto try explicitly to, but to try to solve problems and simply not\ndiscount weird hunches you have in the process.The winds of change originate in the unconscious minds of domain\nexperts.  If you're sufficiently expert in a field, any weird idea\nor apparently irrelevant question that occurs to you is ipso facto\nworth exploring. \n[3]\n Within Y Combinator, when an idea is described\nas crazy, it's a compliment\u2014in fact, on average probably a\nhigher compliment than when an idea is described as good.Startup investors have extraordinary incentives for correcting\nobsolete beliefs.  If they can realize before other investors that\nsome apparently unpromising startup isn't, they can make a huge\namount of money.  But the incentives are more than just financial.\nInvestors' opinions are explicitly tested: startups come to them\nand they have to say yes or no, and then, fairly quickly, they learn\nwhether they guessed right.  The investors who say no to a Google\n(and there were several) will remember it for the rest of their\nlives.Anyone who must in some sense bet on ideas rather than merely\ncommenting on them has similar incentives.  Which means anyone who\nwants such incentives can have them, by turning their comments into\nbets: if you write about a topic in some fairly durable and public\nform, you'll find you worry much more about getting things right\nthan most people would in a casual conversation.\n[4]Another trick I've found to protect myself against obsolete beliefs\nis to focus initially on people rather than ideas. Though the nature\nof future discoveries is hard to predict, I've found I can predict\nquite well what sort of people will make them.  Good new ideas come\nfrom earnest, energetic, independent-minded people.Betting on people over ideas saved me countless times as an investor.\nWe thought Airbnb was a bad idea, for example. But we could tell\nthe founders were earnest, energetic, and independent-minded.\n(Indeed, almost pathologically so.)  So we suspended disbelief and\nfunded them.This too seems a technique that should be generally applicable.\nSurround yourself with the sort of people new ideas come from.  If\nyou want to notice quickly when your beliefs become obsolete, you\ncan't do better than to be friends with the people whose discoveries\nwill make them so.It's hard enough already not to become the prisoner of your own\nexpertise, but it will only get harder, because change is accelerating.\nThat's not a recent trend; change has been accelerating since the\npaleolithic era.  Ideas beget ideas.  I don't expect that to change.\nBut I could be wrong.\nNotes[1]\nMy usual trick is to talk about aspects of the present that\nmost people haven't noticed yet.[2]\nEspecially if they become well enough known that people start\nto identify them with you.  You have to be extra skeptical about\nthings you want to believe, and once a hypothesis starts to be\nidentified with you, it will almost certainly start to be in that\ncategory.[3]\nIn practice \"sufficiently expert\" doesn't require one to be\nrecognized as an expert\u2014which is a trailing indicator in any\ncase.  In many fields a year of focused work plus caring a lot would\nbe enough.[4]\nThough they are public and persist indefinitely, comments on\ne.g. forums and places like Twitter seem empirically to work like\ncasual conversation.  The threshold may be whether what you write\nhas a title.\nThanks to Sam Altman, Patrick Collison, and Robert Morris\nfor reading drafts of this.April 2005\"Suits make a corporate comeback,\" says the New\nYork Times.  Why does this sound familiar?  Maybe because\nthe suit was also back in February,\n\nSeptember\n2004, June\n2004, March\n2004, September\n2003, \n\nNovember\n2002, \nApril 2002,\nand February\n2002.\n\nWhy do the media keep running stories saying suits are back?  Because\nPR firms tell \nthem to.  One of the most surprising things I discovered\nduring my brief business career was the existence of the PR industry,\nlurking like a huge, quiet submarine beneath the news.  Of the\nstories you read in traditional media that aren't about politics,\ncrimes, or disasters, more than half probably come from PR firms.I know because I spent years hunting such \"press hits.\"  Our startup spent\nits entire marketing budget on PR: at a time when we were assembling\nour own computers to save money, we were paying a PR firm $16,000\na month.  And they were worth it.  PR is the news equivalent of\nsearch engine optimization; instead of buying ads, which readers\nignore, you get yourself inserted directly into the stories.  [1]Our PR firm\nwas one of the best in the business.  In 18 months, they got press\nhits in over 60 different publications.  \nAnd we weren't the only ones they did great things for.  \nIn 1997 I got a call from another\nstartup founder considering hiring them to promote his company.  I\ntold him they were PR gods, worth every penny of their outrageous   \nfees.  But I remember thinking his company's name was odd.\nWhy call an auction site \"eBay\"?\nSymbiosisPR is not dishonest.  Not quite.  In fact, the reason the best PR\nfirms are so effective is precisely that they aren't dishonest.\nThey give reporters genuinely valuable information.  A good PR firm\nwon't bug reporters just because the client tells them to; they've\nworked hard to build their credibility with reporters, and they\ndon't want to destroy it by feeding them mere propaganda.If anyone is dishonest, it's the reporters.  The main reason PR  \nfirms exist is that reporters are lazy.  Or, to put it more nicely,\noverworked.  Really they ought to be out there digging up stories\nfor themselves.  But it's so tempting to sit in their offices and\nlet PR firms bring the stories to them.  After all, they know good\nPR firms won't lie to them.A good flatterer doesn't lie, but tells his victim selective truths\n(what a nice color your eyes are). Good PR firms use the same\nstrategy: they give reporters stories that are true, but whose truth\nfavors their clients.For example, our PR firm often pitched stories about how the Web  \nlet small merchants compete with big ones.  This was perfectly true.\nBut the reason reporters ended up writing stories about this\nparticular truth, rather than some other one, was that small merchants\nwere our target market, and we were paying the piper.Different publications vary greatly in their reliance on PR firms.\nAt the bottom of the heap are the trade press, who make most of\ntheir money from advertising and would give the magazines away for\nfree if advertisers would let them.  [2] The average\ntrade publication is a  bunch of ads, glued together by just enough\narticles to make it look like a magazine.  They're so desperate for\n\"content\" that some will print your press releases almost verbatim,\nif you take the trouble to write them to read like articles.At the other extreme are publications like the New York Times\nand the Wall Street Journal.  Their reporters do go out and\nfind their own stories, at least some of the time.  They'll listen \nto PR firms, but briefly and skeptically.  We managed to get press   \nhits in almost every publication we wanted, but we never managed \nto crack the print edition of the Times.  [3]The weak point of the top reporters is not laziness, but vanity.\nYou don't pitch stories to them.  You have to approach them as if\nyou were a specimen under their all-seeing microscope, and make it\nseem as if the story you want them to run is something they thought \nof themselves.Our greatest PR coup was a two-part one.  We estimated, based on\nsome fairly informal math, that there were about 5000 stores on the\nWeb.  We got one paper to print this number, which seemed neutral   \nenough.  But once this \"fact\" was out there in print, we could quote\nit to other publications, and claim that with 1000 users we had 20%\nof the online store market.This was roughly true.  We really did have the biggest share of the\nonline store market, and 5000 was our best guess at its size.  But\nthe way the story appeared in the press sounded a lot more definite.Reporters like definitive statements.  For example, many of the\nstories about Jeremy Jaynes's conviction say that he was one of the\n10 worst spammers.  This \"fact\" originated in Spamhaus's ROKSO list,\nwhich I think even Spamhaus would admit is a rough guess at the top\nspammers.  The first stories about Jaynes cited this source, but\nnow it's simply repeated as if it were part of the indictment.   \n[4]All you can say with certainty about Jaynes is that he was a fairly\nbig spammer.  But reporters don't want to print vague stuff like\n\"fairly big.\"  They want statements with punch, like \"top ten.\" And\nPR firms give them what they want.\nWearing suits, we're told, will make us \n3.6\npercent more productive.BuzzWhere the work of PR firms really does get deliberately misleading is in\nthe generation of \"buzz.\"  They usually feed the same story to    \nseveral different publications at once.  And when readers see similar\nstories in multiple places, they think there is some important trend\nafoot.  Which is exactly what they're supposed to think.When Windows 95 was launched, people waited outside stores\nat midnight to buy the first copies.  None of them would have been\nthere without PR firms, who generated such a buzz in\nthe news media that it became self-reinforcing, like a nuclear chain\nreaction.I doubt PR firms realize it yet, but the Web makes it possible to  \ntrack them at work.  If you search for the obvious phrases, you\nturn up several efforts over the years to place stories about the  \nreturn of the suit.  For example, the Reuters article \n\nthat got picked up by USA\nToday in September 2004.  \"The suit is back,\" it begins.Trend articles like this are almost always the work of\nPR firms.  Once you know how to read them, it's straightforward to\nfigure out who the client is.  With trend stories, PR firms usually\nline up one or more \"experts\" to talk about the industry generally. \nIn this case we get three: the NPD Group, the creative director of\nGQ, and a research director at Smith Barney.  [5] When\nyou get to the end of the experts, look for the client. And bingo, \nthere it is: The Men's Wearhouse.Not surprising, considering The Men's Wearhouse was at that moment \nrunning ads saying \"The Suit is Back.\"  Talk about a successful\npress hit-- a wire service article whose first sentence is your own\nad copy.The secret to finding other press hits from a given pitch\nis to realize that they all started from the same document back at\nthe PR firm.  Search for a few key phrases and the names of the\nclients and the experts, and you'll turn up other variants of this \nstory.Casual\nfridays are out and dress codes are in writes Diane E. Lewis\nin The Boston Globe.  In a remarkable coincidence, Ms. Lewis's\nindustry contacts also include the creative director of GQ.Ripped jeans and T-shirts are out, writes Mary Kathleen Flynn in\nUS News & World Report.  And she too knows the \ncreative director of GQ.Men's suits\nare back writes Nicole Ford in Sexbuzz.Com (\"the ultimate men's\nentertainment magazine\").Dressing\ndown loses appeal as men suit up at the office writes Tenisha\nMercer of The Detroit News.\nNow that so many news articles are online, I suspect you could find\na similar pattern for most trend stories placed by PR firms.  I\npropose we call this new sport \"PR diving,\" and I'm sure there are\nfar more striking examples out there than this clump of five stories.OnlineAfter spending years chasing them, it's now second nature\nto me to recognize press hits for what they are.  But before we\nhired a PR firm I had no idea where articles in the mainstream media\ncame from.  I could tell a lot of them were crap, but I didn't\nrealize why.Remember the exercises in critical reading you did in school, where\nyou had to look at a piece of writing and step back and ask whether\nthe author was telling the whole truth?  If you really want to be\na critical reader, it turns out you have to step back one step\nfurther, and ask not just whether the author is telling the truth,\nbut why he's writing about this subject at all.Online, the answer tends to be a lot simpler.  Most people who\npublish online write what they write for the simple reason that\nthey want to.  You\ncan't see the fingerprints of PR firms all over the articles, as\nyou can in so many print publications-- which is one of the reasons,\nthough they may not consciously realize it, that readers trust\nbloggers more than Business Week.I was talking recently to a friend who works for a\nbig newspaper.  He thought the print media were in serious trouble,\nand that they were still mostly in denial about it.  \"They think\nthe decline is cyclic,\" he said.  \"Actually it's structural.\"In other words, the readers are leaving, and they're not coming\nback.\nWhy? I think the main reason is that the writing online is more honest.\nImagine how incongruous the New York Times article about\nsuits would sound if you read it in a blog:\n   The urge to look corporate-- sleek, commanding,\n  prudent, yet with just a touch of hubris on your well-cut sleeve--\n  is an unexpected development in a time of business disgrace.\n   \nThe problem\nwith this article is not just that it originated in a PR firm.\nThe whole tone is bogus.  This is the tone of someone writing down\nto their audience.Whatever its flaws, the writing you find online\nis authentic.  It's not mystery meat cooked up\nout of scraps of pitch letters and press releases, and pressed into \nmolds of zippy\njournalese.  It's people writing what they think.I didn't realize, till there was an alternative, just how artificial\nmost of the writing in the mainstream media was.  I'm not saying\nI used to believe what I read in Time and Newsweek.  Since high\nschool, at least, I've thought of magazines like that more as\nguides to what ordinary people were being\ntold to think than as  \nsources of information.  But I didn't realize till the last  \nfew years that writing for publication didn't have to mean writing\nthat way.  I didn't realize you could write as candidly and\ninformally as you would if you were writing to a friend.Readers aren't the only ones who've noticed the\nchange.  The PR industry has too.\nA hilarious article\non the site of the PR Society of America gets to the heart of the   \nmatter:\n   Bloggers are sensitive about becoming mouthpieces\n  for other organizations and companies, which is the reason they\n  began blogging in the first place.  \nPR people fear bloggers for the same reason readers\nlike them.  And that means there may be a struggle ahead.  As\nthis new kind of writing draws readers away from traditional media, we\nshould be prepared for whatever PR mutates into to compensate.  \nWhen I think   \nhow hard PR firms work to score press hits in the traditional   \nmedia, I can't imagine they'll work any less hard to feed stories\nto bloggers, if they can figure out how.\nNotes[1] PR has at least   \none beneficial feature: it favors small companies.  If PR didn't  \nwork, the only alternative would be to advertise, and only big\ncompanies can afford that.[2] Advertisers pay \nless for ads in free publications, because they assume readers \nignore something they get for free.  This is why so many trade\npublications nominally have a cover price and yet give away free\nsubscriptions with such abandon.[3] Different sections\nof the Times vary so much in their standards that they're\npractically different papers.  Whoever fed the style section reporter\nthis story about suits coming back would have been sent packing by\nthe regular news reporters.[4] The most striking\nexample I know of this type is the \"fact\" that the Internet worm   \nof 1988 infected 6000 computers. I was there when it was cooked up,\nand this was the recipe: someone guessed that there were about\n60,000 computers attached to the Internet, and that the worm might\nhave infected ten percent of them.Actually no one knows how many computers the worm infected, because\nthe remedy was to reboot them, and this destroyed all traces.  But\npeople like numbers.  And so this one is now replicated\nall over the Internet, like a little worm of its own.[5] Not all were\nnecessarily supplied by the PR firm. Reporters sometimes call a few\nadditional sources on their own, like someone adding a few fresh \nvegetables to a can of soup.\nThanks to Ingrid Basset, Trevor Blackwell, Sarah Harlin, Jessica \nLivingston, Jackie McDonough, Robert Morris, and Aaron Swartz (who\nalso found the PRSA article) for reading drafts of this.Correction: Earlier versions used a recent\nBusiness Week article mentioning del.icio.us as an example\nof a press hit, but Joshua Schachter tells me \nit was spontaneous.May 2004When people care enough about something to do it well, those who\ndo it best tend to be far better than everyone else.  There's a\nhuge gap between Leonardo and second-rate contemporaries like\nBorgognone.  You see the same gap between Raymond Chandler and the\naverage writer of detective novels.  A top-ranked professional chess\nplayer could play ten thousand games against an ordinary club player\nwithout losing once.Like chess or painting or writing novels, making money is a very\nspecialized skill.   But for some reason we treat this skill\ndifferently.  No one complains when a few people surpass all the\nrest at playing chess or writing novels, but when a few people make\nmore money than the rest, we get editorials saying this is wrong.Why?  The pattern of variation seems no different than for any other\nskill.  What causes people to react so strongly when the skill is\nmaking money?I think there are three reasons we treat making money as different:\nthe misleading model of wealth we learn as children; the disreputable\nway in which, till recently, most fortunes were accumulated; and\nthe worry that great variations in income are somehow bad for\nsociety.  As far as I can tell, the first is mistaken, the second\noutdated, and the third empirically false.  Could it be that, in a\nmodern democracy, variation in income is actually a sign of health?The Daddy Model of WealthWhen I was five I thought electricity was created by electric\nsockets.  I didn't realize there were power plants out there\ngenerating it.  Likewise, it doesn't occur to most kids that wealth\nis something that has to be generated.  It seems to be something\nthat flows from parents.Because of the circumstances in which they encounter it, children\ntend to misunderstand wealth.  They confuse it with money.  They\nthink that there is a fixed amount of it.  And they think of it as\nsomething that's distributed by authorities (and so should be\ndistributed equally), rather than something that has to be created\n(and might be created unequally).In fact, wealth is not money.  Money is just a convenient way of\ntrading one form of wealth for another.  Wealth is the underlying\nstuff\u2014the goods and services we buy.  When you travel to a\nrich or poor country, you don't have to look at people's bank\naccounts to tell which kind you're in.  You can see\nwealth\u2014in buildings and streets, in the clothes and the health\nof the people.Where does wealth come from?  People make it.  This was easier to\ngrasp when most people lived on farms, and made many of the things\nthey wanted with their own hands.  Then you could see in the house,\nthe herds, and the granary the wealth that each family created.  It\nwas obvious then too that the wealth of the world was not a fixed\nquantity that had to be shared out, like slices of a pie.  If you\nwanted more wealth, you could make it.This is just as true today, though few of us create wealth directly\nfor ourselves (except for a few vestigial domestic tasks).  Mostly\nwe create wealth for other people in exchange for money, which we\nthen trade for the forms of wealth we want. \n[1]Because kids are unable to create wealth, whatever they\n\nRead the document and answer: What is the best thing to do in San Francisco? Here is the most relevant sentence in the context:"}]